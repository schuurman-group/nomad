#!/usr/bin/env python
"""
This is the driver for the hamiltonian propagation. This driver
reads the checkpoint file, passes the trajectory data (in batches,
if need be) to the Hamiltonian propagation routines, which
are written as dynamically loaded libraries
"""
import os
import sys as sys
import h5py as h5py
import ctypes as ctypes
import numpy as np
from scipy.ndimage.filters import gaussian_filter
import math as math
import nomad.math.constants as constants
import nomad.core.glbl as glbl
import nomad.core.checkpoint as checkpoint
import nomad.analysis.lib_utils as lib_utils
import nomad.analysis.fileio as fileio
import nomad.analysis.plot as plot
import nomad.analysis.plot_defaults as default

chkpt_file     = ''
output_dir     = ''
output_file    = ''
jtype          = ''
tstep          = 0.
jobtypes       = ['geoms', 'trpes']

def init():
    """Initializes the nomad inputs.

    This must be separate from main so that an error which occurs
    before the input file is created will be written to stdout.
    """

    process_arguments(sys.argv)

def process_arguments(args):
    """Process command line arguments."""
    global chkpt_file, output_dir, output_file
    global jtype, jobtypes, tstep

    glbl.paths['cwd']  = os.getcwd()

    if '-chkpt' in sys.argv:
        chkpt_file = args[args.index('-chkpt')+1]
    else:
        chkpt_file = ''

    if '-jobtype' in sys.argv:
        jtype = args[args.index('-jobtype')+1]
    else:
        jtype = ''

    if '-tstep' in sys.argv:
        tstep = float(args[args.index('-tstep')+1])
    else:
        tstep = 5.

    if '-odir' in sys.argv:
        output_dir  = args[args.index('-odir')+1]
    else:
        output_dir  = ''

    if '-geom_files' in sys.argv:
        output_file = args[args.index('-ofile')+1]
    else: 
        output_file = 'geoms'


    if jtype not in jobtypes:
        os.exit('error: '+str(jtype)+' not a valid job type')

    return

#
def main():
    """ main driver routine """
    global input_file, chkpt_file, output_dir, output_file
    global jtype, jobtypes,tstep

    au2fs = 1./constants.fs2au

    # if we're generating geometries, just open chkpt file and
    # read them out at each time step
    if jtype == 'geoms':

        #load the appropriate library
        lib_path  = os.environ['NOMAD']+'/nomad/analysis/lib_traj.so'
        if not os.path.isfile(lib_path):
            raise FileNotFoundError('density library not found: '+lib_path)
        lib_traj = ctypes.cdll.LoadLibrary(lib_path)

        # reset chkpt_file variable to be consistent with the current path
        chkpt = h5py.File(chkpt_file, 'r+', libver='latest')
        checkpoint.read_keywords(chkpt)

        # change the current default checkpoint file path to the checkpoint
        # file we're operating on.
        glbl.paths['chkpt_file'] = chkpt_file
    
        # pass the various run time options to the propagation library
        default_step = float(glbl.properties['default_time_step'])
        step_method = ['nascent', 'static'].index('static')+1
        lib_utils.init_table(lib_traj, default_step, step_method)

        # create the trajectory table
        kwords = lib_utils.create_table(lib_traj, chkpt)

        # load all the trajectories into a library
        kwords = lib_utils.load_trajectories(
                       lib_traj, chkpt, kwords, None, None)

        # FINALLY -- close the checkpoint file
        chkpt.close()

        for ibatch in range(kwords['nbatch']):
            time_final = float(kwords['tbnds'][2*ibatch+1])*au2fs
            n_traj     = int(kwords['ntraj'][ibatch])
            geom_file  = open(output_file+'.'+str(ibatch+1)+'.xyz', 'w')
            prev_step  = dict() 
            offset     = 0
            for time in np.arange(0., time_final, tstep):

                traj_list = lib_utils.traj_retrieve_timestep(
                               lib_traj, kwords, time/au2fs, ibatch, n_traj)
                lib_utils.print_geom_file(traj_list, geom_file, time, prev_step)

                for traj in range(len(traj_list)):
                    prev_step[traj_list[traj].label] = offset + traj
                offset += len(traj_list)

            geom_file.close()

    if jtype == 'trpes':

        inp = default.trpesplot
        fileio.cfg_update(inp, default.inpname['trpesplot'])

        fnames = fileio.get_fnames(inp['seed_files'])
        nseed = len(fnames)

        ebins = np.linspace(inp['emin'] - 3*inp['esig'],
                            inp['emax'] + 3*inp['esig'], inp['nebins'])
        tstrt = inp['tinc']*round((inp['tmin'] - 3*inp['tsig'])/(au2fs*inp['tinc']))
        tbins = np.arange(tstrt, (inp['tmax'] + 3*inp['tsig'])/au2fs + inp['tinc'],
                                  inp['tinc']) - inp['tinc'] // 2
        ecent = (ebins[1:] + ebins[:-1]) / 2
        tcent = au2fs*(tbins[1:] + tbins[:-1]) / 2
        sigma = (inp['tsig'] / (au2fs*(tbins[1]-tbins[0])),
                 inp['esig'] / (ebins[1]-ebins[0]))
        spec = np.empty((nseed, len(tbins)-1, len(ebins)-1))

        for i, fn in enumerate(fnames):
            rawdat = np.genfromtxt(fn).T
            nd = (len(rawdat) - 3) // 2
            times = np.tile(rawdat[0], nd)
            energies = rawdat[3::2].flatten()
            if inp['dyson_norms']:
                wgts = (rawdat[2] * rawdat[4::2]).flatten()
            else:
                wgts = np.tile(rawdat[2], nd)

            stick = np.histogram2d(times, inp['eprobe'] - energies,
                                   bins=(tbins, ebins), weights=wgts)[0]
            spec[i] = gaussian_filter(stick, sigma=sigma)

        total_spec = np.average(spec, axis=0)
        emask = np.logical_and(ecent >= inp['emin'], ecent <= inp['emax'])
        tmask = np.logical_and(tcent >= inp['tmin'], tcent <= inp['tmax'])
        scale = np.max(total_spec[np.ix_(tmask, emask)])
        total_spec /= scale
        kwargs = dict(xlabel='Kinetic Energy / eV', ylabel='Time / fs',
                      xlim=(inp['emin'], inp['emax']),
                      ylim=(inp['tmin'], inp['tmax']))
        header = np.hstack((0, ecent))

        if inp['calc_err']:
            spec /= scale
            total_spec, total_err = populations.error_amps(spec,
                                               nboot=inp['n_bootstrap'],
                                               bthrsh=inp['boot_thrsh'])

            data = np.vstack((tcent, 100*total_err.T)).T
            fileio.write_dat(inp['err_name'], np.vstack((header, data)),
                             charwid=10)
            if inp['err_plot_name'] is not None:
                vmax = np.max(total_err[np.ix_(tmask, emask)])
                total_err[total_err > vmax] = 0
                fig, ax = plot.contourf(ecent, tcent, total_err, **kwargs)
                plot.save(inp['err_plot_name'])

        data = np.vstack((tcent, 100*total_spec.T)).T
        fileio.write_dat(inp['data_name'], np.vstack((header, data)),
                         charwid=10)

        if inp['plot_name'] is not None:
            #fig, ax = plot.heatmap(ebins, tbins, total_spec, **kwargs)
            fig, ax = plot.contourf(ecent, tcent, total_spec, **kwargs)
            plot.save(inp['plot_name'])

    return

#   
if __name__ == '__main__':
    # parse command line arguments
    if '-openmp' in sys.argv:
        glbl.mpi['parallel'] = True

    # initialize
    init()

    # run the main routine
    main()

