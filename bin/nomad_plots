#!/usr/bin/env python
"""
This is the driver for the hamiltonian propagation. This driver
reads the checkpoint file, passes the trajectory data (in batches,
if need be) to the Hamiltonian propagation routines, which
are written as dynamically loaded libraries
"""
import os
import sys as sys
import h5py as h5py
import ctypes as ctypes
import numpy as np
from scipy.ndimage.filters import gaussian_filter
import math as math
import nomad.math.constants as constants
import nomad.core.glbl as glbl
import nomad.core.checkpoint as checkpoint
import nomad.analysis.lib_utils as lib_utils
import nomad.analysis.fileio as fileio
import nomad.analysis.plot as plot
import nomad.analysis.defaults as defaults

input_file  = ''
job_type    = ''
output_dir  = ''
output_file = ''
tstep       = 0.
jobtypes    = ['geoms', 'trpes']
valid_args  = ['jobtype','odir','ofiles','tstep']

def init():
    """Initializes the nomad inputs.

    This must be separate from main so that an error which occurs
    before the input file is created will be written to stdout.
    """

    process_arguments(sys.argv)

def process_arguments(args):
    """Process command line arguments."""
    global input_file, job_type, output_dir, output_file, tstep
    global jobtypes, valid_args

    glbl.paths['cwd']  = os.getcwd()

    if '-'+args[1].strip() not in valid_args:
        input_file = args[1]

    if '-jobtype' in sys.argv:
        job_type = args[args.index('-jobtype')+1]
    else:
        job_type = ''

    if '-ofiles' in sys.argv:
        output_file = args[args.index('-ofile')+1]
    else:
        output_file = 'geoms'

    if '-odir' in sys.argv:
        output_dir  = args[args.index('-odir')+1]
    else:
        output_dir  = ''

    if '-tstep' in sys.argv:
        tstep = float(args[args.index('-tstep')+1])
    else:
        tstep = 5.

    if job_type not in jobtypes:
        os.exit('error: '+str(jtype)+' not a valid job type')

    if job_type == 'geoms' and input_file == '':
        os.exit('error: checkpoint file needs to be specified'+
                'in order to generate geometries')

    return

#
def main():
    """ main driver routine """
    global input_file, job_type, output_dir, output_file, tstep

    au2fs = 1./constants.fs2au

    # if we're generating geometries, just open chkpt file and
    # read them out at each time step
    if job_type == 'geoms':

        #load the appropriate library
        lib_path  = os.environ['NOMAD']+'/nomad/analysis/lib_traj.so'
        if not os.path.isfile(lib_path):
            raise FileNotFoundError('density library not found: '+lib_path)
        lib_traj = ctypes.cdll.LoadLibrary(lib_path)

        # reset chkpt_file variable to be consistent with the current path
        chkpt = h5py.File(input_file, 'r+', libver='latest')
        checkpoint.read_keywords(chkpt)

        # change the current default checkpoint file path to the checkpoint
        # file we're operating on.
        glbl.paths['chkpt_file'] = input_file
    
        # pass the various run time options to the propagation library
        default_step = float(glbl.properties['default_time_step'])
        step_method = ['nascent', 'static'].index('static')+1
        lib_utils.init_table(lib_traj, default_step, step_method)

        # create the trajectory table
        kwords = lib_utils.create_table(lib_traj, chkpt)

        # load all the trajectories into a library
        kwords = lib_utils.load_trajectories(
                       lib_traj, chkpt, kwords, None, None)

        # FINALLY -- close the checkpoint file
        chkpt.close()

        for ibatch in range(kwords['nbatch']):
            batch      = int(kwords['batches'][ibatch])
            n_traj     = int(kwords['ntraj'][ibatch])
            time_final = float(kwords['tbnds'][2*ibatch+1])*au2fs
            geom_file  = open(output_file+'.'+str(batch+1)+'.xyz', 'w')
            prev_step  = dict() 
            offset     = 0
            for time in np.arange(0., time_final, tstep):

                traj_list = lib_utils.traj_retrieve_timestep(
                               lib_traj, kwords, time/au2fs, batch, n_traj)
                lib_utils.print_geom_file(traj_list, geom_file, time, prev_step)

                for traj in range(len(traj_list)):
                    prev_step[traj_list[traj].label] = offset + traj
                offset += len(traj_list)

            geom_file.close()

    if job_type == 'trpes':

        # first set all the defaults
        inp = defaults.trpesplot
 
        # update the defaults if an input file is specified
        if input_file == '':
            input_file = defaults.inpname['trpesplot']
        fileio.cfg_update(inp, input_file)

        # load spectral information
        fnames = fileio.get_fnames(inp['seed_files'])
        nseed = len(fnames)

        ebins = np.linspace(inp['emin'] - 3*inp['esig'],
                            inp['emax'] + 3*inp['esig'], inp['nebins'])
        tstrt = inp['tinc']*round((inp['tmin'] - 3*inp['tsig'])/(au2fs*inp['tinc']))
        tbins = np.arange(tstrt, (inp['tmax'] + 3*inp['tsig'])/au2fs + inp['tinc'],
                                  inp['tinc']) - inp['tinc'] // 2
        ecent = (ebins[1:] + ebins[:-1]) / 2
        tcent = au2fs*(tbins[1:] + tbins[:-1]) / 2
        sigma = (inp['tsig'] / (au2fs*(tbins[1]-tbins[0])),
                 inp['esig'] / (ebins[1]-ebins[0]))
        spec = np.empty((nseed, len(tbins)-1, len(ebins)-1))

        for i, fn in enumerate(fnames):
            rawdat = np.genfromtxt(fn).T
            nd = (len(rawdat) - 3) // 2
            times = np.tile(rawdat[0], nd)
            energies = rawdat[3::2].flatten()
            if inp['dyson_norms']:
                wgts = (rawdat[2] * rawdat[4::2]).flatten()
            else:
                wgts = np.tile(rawdat[2], nd)

            stick = np.histogram2d(times, inp['eprobe'] - energies,
                                   bins=(tbins, ebins), weights=wgts)[0]
            spec[i] = gaussian_filter(stick, sigma=sigma)

        total_spec = np.average(spec, axis=0)
        emask = np.logical_and(ecent >= inp['emin'], ecent <= inp['emax'])
        tmask = np.logical_and(tcent >= inp['tmin'], tcent <= inp['tmax'])
        scale = np.max(total_spec[np.ix_(tmask, emask)])
        total_spec /= scale
        kwargs = dict(xlabel='Kinetic Energy / eV', ylabel='Time / fs',
                      xlim=(inp['emin'], inp['emax']),
                      ylim=(inp['tmin'], inp['tmax']))
        header = np.hstack((0, ecent))

        if inp['calc_err']:
            spec /= scale
            total_spec, total_err = populations.error_amps(spec,
                                               nboot=inp['n_bootstrap'],
                                               bthrsh=inp['boot_thrsh'])

            data = np.vstack((tcent, 100*total_err.T)).T
            fileio.write_dat(inp['err_name'], np.vstack((header, data)),
                             charwid=10)
            if inp['err_plot_name'] is not None:
                vmax = np.max(total_err[np.ix_(tmask, emask)])
                total_err[total_err > vmax] = 0
                fig, ax = plot.contourf(ecent, tcent, total_err, **kwargs)
                plot.save(inp['err_plot_name'])

        data = np.vstack((tcent, 100*total_spec.T)).T
        fileio.write_dat(inp['data_name'], np.vstack((header, data)),
                         charwid=10)

        if inp['plot_name'] is not None:
            #fig, ax = plot.heatmap(ebins, tbins, total_spec, **kwargs)
            fig, ax = plot.contourf(ecent, tcent, total_spec, **kwargs)
            plot.save(inp['plot_name'])

    return

#   
if __name__ == '__main__':
    # parse command line arguments
    if '-openmp' in sys.argv:
        glbl.mpi['parallel'] = True

    # initialize
    init()

    # run the main routine
    main()

